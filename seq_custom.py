# -*- coding: utf-8 -*-
"""seq-custom.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PoOC4lt3zxzt2SODVXXPtxWeHa_3GzH_
"""

# Commented out IPython magic to ensure Python compatibility.
from __future__ import absolute_import, division, print_function, unicode_literals
try:
  # Use the %tensorflow_version magic if in colab.
#   %tensorflow_version 2.x
except Exception:
  pass

from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf

from tensorflow.keras.layers import Dense, Flatten, Conv2D
from tensorflow.keras import Model

import os
import glob
import shutil
import numpy as np
import matplotlib.pyplot as plt

# Load the Drive helper and mount
from google.colab import drive

from PIL import Image
from PIL import ImageColor
from PIL import ImageDraw
from PIL import ImageFont
from PIL import ImageOps

import csv
import datetime

from matplotlib import cm

import random

# This will prompt for authorization.
drive.mount('/content/gdrive', force_remount=True)

"""Different Data-aug filters I tried"""

def zoom_at(img_path, saved_location):
    img = Image.open(img_path)
    t = img.size
    img = img.crop((w/6, h/6, 
                    w - w/6,  h - h/6))
    img = img.resize(w,h)
    img.save(saved_location)

def gaussianNoise(image_path, saved_location):
  pic = Image.open(image_path)
  image = np.array(pic)
  row,col,ch= image.shape
  mean = 0
  var = 0.5
  sigma = var**0.5
  gauss = np.random.normal(mean,sigma,(row,col,ch))
  gauss = gauss.reshape(row,col,ch)
  noisy = image + gauss
  new_noisy = Image.fromarray(noisy.astype('uint8'), 'RGB')
  new_noisy.save(saved_location)

def rotate(image_path, saved_location):
    image_obj = Image.open(image_path)
    rotated_image = image_obj.rotate(random.randint(1,90))
    rotated_image.save(saved_location)

def flip_image(image_path, saved_location):
    image_obj = Image.open(image_path)
    rotated_image = image_obj.transpose(Image.FLIP_LEFT_RIGHT)
    rotated_image.save(saved_location)

def flip_image_up_down(image_path, saved_location):
    image_obj = Image.open(image_path)
    rotated_image = image_obj.transpose(Image.FLIP_TOP_BOTTOM)
    rotated_image.save(saved_location)

"""python code to get class name (theres also a tensorflow version)"""

def getClass(dir):
  classN = ""
  i = len(dir) -1
  k = ''
  while k != '/':
    k = dir[i]
    classN = k + classN
    i-=1

  return classN[1:len(dir)]

"""these are all functions to organize our data correctly"""

def outputfilepath(filename):
  val = filename.replace("val", "limited-val")
  return val

classes = ['cabbage','ringlet','sulphur','monarch-milkweed']
base_directory = "/content/gdrive/My Drive/Capstone 2019/ImageDataset/"

base_train_photos = "/content/gdrive/My Drive/Capstone 2019/ImageDataset/Dec-test/dec-trial/train"
base_val_directory = "/content/gdrive/My Drive/Capstone 2019/ImageDataset/Dec-test/dec-trial/val/"
base_test_directory = "/content/gdrive/My Drive/Capstone 2019/ImageDataset/Dec-test/dec-trial/test/"
base_data_aug =  "/content/gdrive/My Drive/Capstone 2019/ImageDataset/Dec-test/dec-trial/data-aug/"

i = 0
for dir in classes:
  class_path = os.path.join(base_directory, dir + "/croppedphotos/")
  img_path =  glob.glob(os.path.join(class_path, '*'))
  print("{}: {} Images".format(class_path, len(img_path)))
  train,val,test = img_path[:round(len(img_path)*0.6)], img_path[round(len(img_path)*0.6):round(len(img_path)*0.8)], img_path[round(len(img_path)*.8):]
  cl = dir
  print(os.path.join(base_exp_train, 'train', cl))
  for t in train:
    shutil.copy(t, os.path.join(base_exp_train, 'train', cl))
  print("done with " + cl + " train" )
  for v in val:
    shutil.copy(v, os.path.join(base_exp_train, 'val', cl))
  print("done with " + cl + " val" )
  for ts in test:
    shutil.copy(ts, os.path.join(base_exp_train, 'test', cl))
  print("done with " + cl + " test" )

it =0
aug = ["rot", "flip_up", "flip_side"]
for dir in glob.glob( os.path.join(base_exp_train,  '*') ):
  if os.path.isdir(dir):
      for filename in os.listdir(dir):
        print(outputfilepath(dir + "/" + filename))
        
        if it < 779:
          shutil.copy(dir + "/" + filename, outputfilepath(dir + "/" + filename))
          i = random.randint(0,2)
          if aug[i] == "rot":
            rotate(dir + "/" + filename, outputfilepath(dir + "/rotate_" + filename))
          elif aug[i] == "flip_up":
            flip_image(dir + "/" + filename, outputfilepath(dir + "/flip_" + filename))
          else:
            flip_image_up_down(dir + "/" + filename, outputfilepath(dir + "/flip_ud_" + filename))
        it += 1
      it = 0

!ls '/content/gdrive/My Drive/Capstone 2019/ImageDataset/'

it =0
for dir in glob.glob( os.path.join(base_val_directory,  '*') ):
  print(dir)
  for filename in os.listdir(dir):
    it+=1
  print(it)
  it = 0

"""tensorflow function to take apth and make a container for a dataset"""

train_data = tf.data.Dataset.list_files(str(base_data_aug  + '*/*'))
val_data = tf.data.Dataset.list_files(str(base_val_directory  + '*/*'))
test_data = tf.data.Dataset.list_files(str(base_test_directory + '*/*'))



CLASS_NAMES = np.array(['cabbage','ringlet','sulphur','monarch-milkweed'])
print(CLASS_NAMES)
BATCH_SIZE = 100

"""turns path into img and label pair"""

def get_label(file_path):
  # convert the path to a list of path components
  parts = tf.strings.split(file_path, '/')
  # The second to last is the class-directory
  return parts[-2] == CLASS_NAMES

def decode_img(img):
  # convert the compressed string to a 3D uint8 tensor
  img = tf.image.decode_jpeg(img, channels=3)
  # Use `convert_image_dtype` to convert to floats in the [0,1] range.
  img = tf.image.convert_image_dtype(img, tf.float32)
  # resize the image to the desired size.
  return tf.image.resize(img, [150, 150])

def process_path(file_path):
  label = get_label(file_path)
  # load the raw data from the file as a string
  img = tf.io.read_file(file_path)
  img = decode_img(img)
  return img, label

# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.
labeled_train_data = train_data.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE).shuffle(1000).batch(100)
labeled_val_data = val_data.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(100)

from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Activation
from tensorflow.keras import Model,  regularizers, initializers

model = tf.keras.Sequential([
  tf.keras.layers.Conv2D(16, 3, padding='same', input_shape=(150, 150, 3),  kernel_regularizer=regularizers.l2(0.0005)),  # input shape required
  tf.keras.layers.BatchNormalization(),
  tf.keras.layers.Activation('relu'),
  tf.keras.layers.MaxPooling2D(2, 2),
  tf.keras.layers.Conv2D(32, 3, padding='same',  kernel_regularizer=regularizers.l2(0.0005)), 
  tf.keras.layers.BatchNormalization(),
  tf.keras.layers.Activation('relu'),
  tf.keras.layers.MaxPooling2D(2, 2),
  tf.keras.layers.Conv2D(64, 3, padding='same', kernel_regularizer=regularizers.l2(0.0005)),
  tf.keras.layers.BatchNormalization(),
  tf.keras.layers.Activation('relu'),
  tf.keras.layers.MaxPooling2D(2, 2),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dropout(0.5),
  tf.keras.layers.Dense(512, kernel_regularizer=regularizers.l2(0.0005)),
  tf.keras.layers.BatchNormalization(),
  tf.keras.layers.Activation('relu'),
  tf.keras.layers.Dropout(0.5),
  tf.keras.layers.Dense(4, activation='softmax')
])

loss_object = tf.keras.losses.SparseCategoricalCrossentropy()

optimizer = tf.keras.optimizers.Adam(lr=0.0005)

train_loss = tf.keras.metrics.Mean(name='train_loss')
train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')

test_loss = tf.keras.metrics.Mean(name='test_loss')
test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')

#I used these when I want to have graphs of my training process
current_time = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
train_log_dir = 'logs/gradient_tape/' + current_time + '/train'
test_log_dir = 'logs/gradient_tape/' + current_time + '/test'
train_summary_writer = tf.summary.create_file_writer(train_log_dir)
test_summary_writer = tf.summary.create_file_writer(test_log_dir)

@tf.function
def train_step(images, labels):
  with tf.GradientTape() as tape:
    predictions = model(images)
    loss = loss_object(labels, predictions)
  gradients = tape.gradient(loss, model.trainable_variables)
  optimizer.apply_gradients(zip(gradients, model.trainable_variables))

  train_loss(loss)
  train_accuracy(labels, predictions)

@tf.function
def test_step(images, labels):
  predictions = model(images)
  t_loss = loss_object(labels, predictions)

  test_loss(t_loss)
  test_accuracy(labels, predictions)

def labelList(labels):
    d = []
    for lists in labels:
      curr = lists.numpy()
      for i in range(len(curr)):
        if(curr[i] == True):
          d.append(i)
    return tf.convert_to_tensor(d)

"""our training loop"""

EPOCHS = 17

i =0; 
for epoch in range(EPOCHS):
  for images, labels in labeled_train_data:
    l = labelList(labels)
    train_step(images, l)
    print("batch " + str(i) + " done" )
    i+=1

  for test_images, test_labels in labeled_val_data:
    l = labelList(test_labels)
    test_step(test_images, l)

  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'
  print(template.format(epoch+1,
                        train_loss.result(),
                        train_accuracy.result()*100,
                        test_loss.result(),
                        test_accuracy.result()*100))

  # Reset the metrics for the next epoch
  train_loss.reset_states()
  train_accuracy.reset_states()
  test_loss.reset_states()
  test_accuracy.reset_states()

def getClass(dir):
  classN = ""
  i = len(dir) -1
  k = ''
  while k != '/':
    k = dir[i]
    classN = k + classN
    i-=1

  return classN[1:len(dir)]

s = "/content/gdrive/My Drive/Capstone 2019/ImageDataset/test/cabbage"
print(getClass(s))

"""test perdictions"""

from tensorflow.keras.preprocessing import image
with open('predictions.csv', 'w', newline='') as csvfile:
    fieldnames = ['image_name', 'class_pred', 'percentage', 'pos_pred']
    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

    writer.writeheader()
    for dir in glob.glob( os.path.join( base_test_directory,  '*') ):
      if os.path.isdir(dir):
        currClass = getClass(dir)
        for filename in os.listdir(dir):
          img = image.load_img(dir + "/" + filename, target_size=(150, 150))
          img_tensor = image.img_to_array(img)
          img_tensor = np.expand_dims(img_tensor, axis=0)
          img_tensor = tf.image.convert_image_dtype(img_tensor, tf.float32)
          predictions = model(img_tensor)
          for i, logits in enumerate(predictions):
            class_idx = tf.argmax(logits).numpy()
            p = tf.nn.softmax(logits)[class_idx]
            name = CLASS_NAMES[class_idx]
            pos_pred = "NO"
            if(name == currClass):
              pos_pred = "YES"
            writer.writerow({'image_name': i, 'class_pred': name, 'percentage': 100*p, 'pos_pred': pos_pred })
            print("Example {} prediction: {} ({:4.1f}%)".format(i, name, 100*p))

"""saving and loading model"""

tf.saved_model.save(model, "/tmp/lil_yo_late")

!saved_model_cli show --dir /tmp/lil_yo_late --tag_set serve --signature_def serving_default

from google.colab import files
files.download('/tmp/lil_yo_late/saved_model.pb')